#!/usr/bin/env python3
"""
æ··åˆé‡‡æ ·ç­–ç•¥å¯è§†åŒ–å·¥å…·

ç”¨äºåˆ†æå’Œå¯è§†åŒ–æ··åˆé‡‡æ ·ç­–ç•¥çš„æ•ˆæœï¼ŒåŒ…æ‹¬ï¼š
1. çƒå½¢è·¯å¾„å¯è§†åŒ–
2. ç›¸æœºè½¨è¿¹åˆ†æ
3. è§†è§’è¦†ç›–åº¦è®¡ç®—
4. æ€§èƒ½æŒ‡æ ‡ç»Ÿè®¡
"""

import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import torch
import json
from pathlib import Path
from typing import List, Dict, Tuple
import argparse

class HybridSamplingVisualizer:
    """æ··åˆé‡‡æ ·ç­–ç•¥å¯è§†åŒ–å™¨"""
    
    def __init__(self, result_dir: str):
        self.result_dir = Path(result_dir)
        self.camera_data = {}
        self.load_camera_data()
    
    def load_camera_data(self):
        """åŠ è½½ç›¸æœºæ•°æ®"""
        json_files = list(self.result_dir.glob("difix3d_camera_poses_step_*.json"))
        if json_files:
            latest_file = max(json_files, key=lambda x: x.stat().st_mtime)
            with open(latest_file, 'r', encoding='utf-8') as f:
                self.camera_data = json.load(f)
            print(f"âœ… åŠ è½½ç›¸æœºæ•°æ®: {latest_file}")
        else:
            print("âš ï¸ æœªæ‰¾åˆ°ç›¸æœºæ•°æ®æ–‡ä»¶")
    
    def visualize_spherical_path(self, save_path: str = None):
        """å¯è§†åŒ–çƒå½¢è·¯å¾„"""
        if not self.camera_data:
            print("âŒ æ²¡æœ‰ç›¸æœºæ•°æ®å¯ä¾›å¯è§†åŒ–")
            return
        
        fig = plt.figure(figsize=(15, 5))
        
        # å­å›¾1: è®­ç»ƒç›¸æœºåˆ†å¸ƒ
        ax1 = fig.add_subplot(131, projection='3d')
        self._plot_train_cameras(ax1)
        ax1.set_title('è®­ç»ƒç›¸æœºåˆ†å¸ƒ')
        
        # å­å›¾2: DiFix3Dè™šæ‹Ÿç›¸æœºåˆ†å¸ƒ
        ax2 = fig.add_subplot(132, projection='3d')
        self._plot_difix3d_cameras(ax2)
        ax2.set_title('DiFix3Dè™šæ‹Ÿç›¸æœºåˆ†å¸ƒ')
        
        # å­å›¾3: æ··åˆåˆ†å¸ƒ
        ax3 = fig.add_subplot(133, projection='3d')
        self._plot_combined_cameras(ax3)
        ax3.set_title('æ··åˆç›¸æœºåˆ†å¸ƒ')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š å¯è§†åŒ–å›¾åƒå·²ä¿å­˜: {save_path}")
        
        plt.show()
    
    def _plot_train_cameras(self, ax):
        """ç»˜åˆ¶è®­ç»ƒç›¸æœº"""
        if 'train_cameras' not in self.camera_data:
            return
        
        train_cameras = self.camera_data['train_cameras']
        positions = np.array([cam['position'] for cam in train_cameras])
        
        ax.scatter(positions[:, 0], positions[:, 1], positions[:, 2], 
                  c='blue', s=50, alpha=0.7, label='è®­ç»ƒç›¸æœº')
        
        # ç»˜åˆ¶ç›¸æœºæœå‘
        for i, cam in enumerate(train_cameras[:10]):  # åªæ˜¾ç¤ºå‰10ä¸ª
            pos = np.array(cam['position'])
            rot_matrix = np.array(cam['rotation_matrix'])
            direction = -rot_matrix[:, 2]  # ç›¸æœºæœå‘
            ax.quiver(pos[0], pos[1], pos[2], 
                     direction[0], direction[1], direction[2],
                     length=0.1, color='blue', alpha=0.5)
        
        ax.set_xlabel('X')
        ax.set_ylabel('Y')
        ax.set_zlabel('Z')
        ax.legend()
    
    def _plot_difix3d_cameras(self, ax):
        """ç»˜åˆ¶DiFix3Dè™šæ‹Ÿç›¸æœº"""
        if 'difix3d_virtual_camera_batches' not in self.camera_data:
            return
        
        all_positions = []
        colors = ['red', 'green', 'orange', 'purple', 'brown']
        
        for batch_idx, batch in enumerate(self.camera_data['difix3d_virtual_camera_batches']):
            positions = np.array([cam['position'] for cam in batch['cameras']])
            all_positions.extend(positions)
            
            color = colors[batch_idx % len(colors)]
            ax.scatter(positions[:, 0], positions[:, 1], positions[:, 2], 
                      c=color, s=30, alpha=0.6, 
                      label=f'æ‰¹æ¬¡ {batch_idx+1} ({len(positions)}ä¸ª)')
        
        if all_positions:
            all_positions = np.array(all_positions)
            # ç»˜åˆ¶çƒå½¢è·¯å¾„ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            self._draw_sphere_path(ax, all_positions)
        
        ax.set_xlabel('X')
        ax.set_ylabel('Y')
        ax.set_zlabel('Z')
        ax.legend()
    
    def _plot_combined_cameras(self, ax):
        """ç»˜åˆ¶æ··åˆç›¸æœºåˆ†å¸ƒ"""
        # è®­ç»ƒç›¸æœº
        if 'train_cameras' in self.camera_data:
            train_cameras = self.camera_data['train_cameras']
            train_positions = np.array([cam['position'] for cam in train_cameras])
            ax.scatter(train_positions[:, 0], train_positions[:, 1], train_positions[:, 2], 
                      c='blue', s=50, alpha=0.7, label='è®­ç»ƒç›¸æœº')
        
        # DiFix3Dè™šæ‹Ÿç›¸æœº
        if 'difix3d_virtual_camera_batches' in self.camera_data:
            all_virtual_positions = []
            for batch in self.camera_data['difix3d_virtual_camera_batches']:
                positions = np.array([cam['position'] for cam in batch['cameras']])
                all_virtual_positions.extend(positions)
            
            if all_virtual_positions:
                all_virtual_positions = np.array(all_virtual_positions)
                ax.scatter(all_virtual_positions[:, 0], all_virtual_positions[:, 1], all_virtual_positions[:, 2], 
                          c='red', s=30, alpha=0.6, label='DiFix3Dè™šæ‹Ÿç›¸æœº')
        
        ax.set_xlabel('X')
        ax.set_ylabel('Y')
        ax.set_zlabel('Z')
        ax.legend()
    
    def _draw_sphere_path(self, ax, positions: np.ndarray):
        """ç»˜åˆ¶çƒå½¢è·¯å¾„"""
        if len(positions) < 3:
            return
        
        # è®¡ç®—åœºæ™¯ä¸­å¿ƒ
        center = np.mean(positions, axis=0)
        
        # è®¡ç®—çƒå½¢åŠå¾„
        distances = np.linalg.norm(positions - center, axis=1)
        radius = np.mean(distances)
        
        # ç»˜åˆ¶çƒå½¢è·¯å¾„
        u = np.linspace(0, 2 * np.pi, 20)
        v = np.linspace(0, np.pi, 20)
        x = center[0] + radius * np.outer(np.cos(u), np.sin(v))
        y = center[1] + radius * np.outer(np.sin(u), np.sin(v))
        z = center[2] + radius * np.outer(np.ones(np.size(u)), np.cos(v))
        
        ax.plot_surface(x, y, z, alpha=0.1, color='gray')
        
        # æ ‡è®°åœºæ™¯ä¸­å¿ƒ
        ax.scatter(center[0], center[1], center[2], c='black', s=100, marker='*', label='åœºæ™¯ä¸­å¿ƒ')
    
    def analyze_coverage(self) -> Dict:
        """åˆ†æè§†è§’è¦†ç›–åº¦"""
        if not self.camera_data:
            return {}
        
        analysis = {
            'train_cameras': 0,
            'difix3d_batches': 0,
            'total_virtual_cameras': 0,
            'coverage_metrics': {}
        }
        
        # ç»Ÿè®¡ç›¸æœºæ•°é‡
        if 'train_cameras' in self.camera_data:
            analysis['train_cameras'] = len(self.camera_data['train_cameras'])
        
        if 'difix3d_virtual_camera_batches' in self.camera_data:
            analysis['difix3d_batches'] = len(self.camera_data['difix3d_virtual_camera_batches'])
            total_virtual = sum(len(batch['cameras']) for batch in self.camera_data['difix3d_virtual_camera_batches'])
            analysis['total_virtual_cameras'] = total_virtual
        
        # è®¡ç®—è¦†ç›–åº¦æŒ‡æ ‡
        all_positions = []
        
        # æ·»åŠ è®­ç»ƒç›¸æœºä½ç½®
        if 'train_cameras' in self.camera_data:
            train_positions = np.array([cam['position'] for cam in self.camera_data['train_cameras']])
            all_positions.extend(train_positions)
        
        # æ·»åŠ è™šæ‹Ÿç›¸æœºä½ç½®
        if 'difix3d_virtual_camera_batches' in self.camera_data:
            for batch in self.camera_data['difix3d_virtual_camera_batches']:
                positions = np.array([cam['position'] for cam in batch['cameras']])
                all_positions.extend(positions)
        
        if all_positions:
            all_positions = np.array(all_positions)
            analysis['coverage_metrics'] = self._calculate_coverage_metrics(all_positions)
        
        return analysis
    
    def _calculate_coverage_metrics(self, positions: np.ndarray) -> Dict:
        """è®¡ç®—è¦†ç›–åº¦æŒ‡æ ‡"""
        metrics = {}
        
        # è®¡ç®—ç©ºé—´åˆ†å¸ƒ
        center = np.mean(positions, axis=0)
        distances = np.linalg.norm(positions - center, axis=1)
        
        metrics['spatial_center'] = center.tolist()
        metrics['mean_distance'] = float(np.mean(distances))
        metrics['std_distance'] = float(np.std(distances))
        metrics['min_distance'] = float(np.min(distances))
        metrics['max_distance'] = float(np.max(distances))
        
        # è®¡ç®—è§’åº¦åˆ†å¸ƒï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        if len(positions) > 1:
            # è®¡ç®—ç›¸å¯¹äºä¸­å¿ƒçš„è§’åº¦åˆ†å¸ƒ
            relative_positions = positions - center
            angles = np.arctan2(relative_positions[:, 1], relative_positions[:, 0])
            metrics['angle_std'] = float(np.std(angles))
            metrics['angle_range'] = float(np.max(angles) - np.min(angles))
        
        return metrics
    
    def generate_report(self, save_path: str = None):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        analysis = self.analyze_coverage()
        
        report = f"""
# æ··åˆé‡‡æ ·ç­–ç•¥åˆ†ææŠ¥å‘Š

## ç›¸æœºç»Ÿè®¡
- è®­ç»ƒç›¸æœºæ•°é‡: {analysis.get('train_cameras', 0)}
- DiFix3Dæ‰¹æ¬¡æ•°é‡: {analysis.get('difix3d_batches', 0)}
- DiFix3Dè™šæ‹Ÿç›¸æœºæ€»æ•°: {analysis.get('total_virtual_cameras', 0)}
- ç›¸æœºæ€»æ•°: {analysis.get('train_cameras', 0) + analysis.get('total_virtual_cameras', 0)}

## è¦†ç›–åº¦æŒ‡æ ‡
"""
        
        if 'coverage_metrics' in analysis and analysis['coverage_metrics']:
            metrics = analysis['coverage_metrics']
            report += f"""
- ç©ºé—´ä¸­å¿ƒ: {metrics.get('spatial_center', 'N/A')}
- å¹³å‡è·ç¦»: {metrics.get('mean_distance', 0):.3f}
- è·ç¦»æ ‡å‡†å·®: {metrics.get('std_distance', 0):.3f}
- æœ€å°è·ç¦»: {metrics.get('min_distance', 0):.3f}
- æœ€å¤§è·ç¦»: {metrics.get('max_distance', 0):.3f}
- è§’åº¦æ ‡å‡†å·®: {metrics.get('angle_std', 0):.3f}
- è§’åº¦èŒƒå›´: {metrics.get('angle_range', 0):.3f}
"""
        
        report += f"""
## å»ºè®®
- å¦‚æœè·ç¦»æ ‡å‡†å·®è¿‡å¤§ï¼Œè€ƒè™‘è°ƒæ•´çƒå½¢è·¯å¾„åŠå¾„
- å¦‚æœè§’åº¦èŒƒå›´è¿‡å°ï¼Œè€ƒè™‘å¢åŠ çƒå½¢è·¯å¾„ç‚¹æ•°
- å¦‚æœè™šæ‹Ÿç›¸æœºæ•°é‡ä¸è¶³ï¼Œè€ƒè™‘å¢åŠ æ’å¸§æ•°é‡

## é…ç½®ä¼˜åŒ–
åŸºäºå½“å‰åˆ†æï¼Œå»ºè®®çš„é…ç½®å‚æ•°ï¼š
- spherical_path_radius: {analysis.get('coverage_metrics', {}).get('mean_distance', 0.2) * 0.8:.3f}
- spherical_path_points: {max(20, analysis.get('total_virtual_cameras', 0) // 2)}
- camera_perturbation_translation: {analysis.get('coverage_metrics', {}).get('std_distance', 0.05) * 0.5:.3f}
"""
        
        print(report)
        
        if save_path:
            with open(save_path, 'w', encoding='utf-8') as f:
                f.write(report)
            print(f"ğŸ“„ åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {save_path}")
        
        return report

def main():
    parser = argparse.ArgumentParser(description='æ··åˆé‡‡æ ·ç­–ç•¥å¯è§†åŒ–å·¥å…·')
    parser.add_argument('--result_dir', type=str, required=True, help='ç»“æœç›®å½•è·¯å¾„')
    parser.add_argument('--save_plot', type=str, help='ä¿å­˜å¯è§†åŒ–å›¾åƒè·¯å¾„')
    parser.add_argument('--save_report', type=str, help='ä¿å­˜åˆ†ææŠ¥å‘Šè·¯å¾„')
    parser.add_argument('--show_plot', action='store_true', help='æ˜¾ç¤ºå¯è§†åŒ–å›¾åƒ')
    
    args = parser.parse_args()
    
    # åˆ›å»ºå¯è§†åŒ–å™¨
    visualizer = HybridSamplingVisualizer(args.result_dir)
    
    # ç”Ÿæˆå¯è§†åŒ–
    if args.show_plot or args.save_plot:
        visualizer.visualize_spherical_path(args.save_plot)
    
    # ç”Ÿæˆåˆ†ææŠ¥å‘Š
    visualizer.generate_report(args.save_report)

if __name__ == "__main__":
    main()

